{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine translation Korean to English\n",
    "##### 데이터출처: AiHub 한-영 말뭉치 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from jupyter_helpers import *\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18378265822269684514\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# GPU check\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 불러오기\n",
    "#### 구어체의 한-영 말뭉치 데이터를 불러왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   SID     400000 non-null  int64 \n",
      " 1   원문      400000 non-null  object\n",
      " 2   번역문     400000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_excel('C:/Users/mark/Desktop/machine_translator_project/data/1_구어체(1)_200226 (1).xlsx')\n",
    "df2 = pd.read_excel('C:/Users/mark/Desktop/machine_translator_project/data/1_구어체(1)_200226.xlsx')\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "print(df.info()) # 400,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor = df['원문'].tolist()\n",
    "eng = df['번역문'].tolist()\n",
    "#print(len(kor))\n",
    "#print(len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en 1번째 줄:  'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
      "small_vocab_kr 1번째 줄:  Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.\n",
      "small_vocab_en 2번째 줄:  씨티은행에서 일하세요?\n",
      "small_vocab_kr 2번째 줄:  Do you work at a City bank?\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(2):\n",
    "    print('small_vocab_en {}번째 줄:  {}'.format(sample_i + 1, kor[sample_i]))\n",
    "    print('small_vocab_kr {}번째 줄:  {}'.format(sample_i + 1, eng[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4271602개의 한국어 단어\n",
      "213041개의 유일한 한국어 단어\n",
      "가장 출현빈도가 높은 10개의 한국어 단어: \n",
      "\"나는\" \"수\" \"저는\" \"이\" \"있습니다.\" \"내가\" \"우리는\" \"그\" \"있는\" \"당신이\"\n",
      "\n",
      "4271602개의 영어단어\n",
      "79176개의 유일한 영어단어\n",
      "가장 출현빈도가 높은 10개의 영어 단어: \n",
      "\"the\" \"I\" \"to\" \"a\" \"you\" \"is\" \"and\" \"of\" \"in\" \"for\"\n"
     ]
    }
   ],
   "source": [
    "kor_counter = collections.Counter([word for sentence in kor for word in sentence.split()])\n",
    "eng_counter = collections.Counter([word for sentence in eng for word in sentence.split()])\n",
    "\n",
    "print('{}개의 한국어 단어'.format(len([word for sentence in eng for word in sentence.split()])))\n",
    "print('{}개의 유일한 한국어 단어'.format(len(kor_counter)))\n",
    "print('가장 출현빈도가 높은 10개의 한국어 단어: ')\n",
    "print('\"' + '\" \"'.join(list(zip(*kor_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "\n",
    "print('{}개의 영어단어'.format(len([word for sentence in eng for word in sentence.split()])))\n",
    "print('{}개의 유일한 영어단어'.format(len(eng_counter)))\n",
    "print('가장 출현빈도가 높은 10개의 영어 단어: ')\n",
    "print('\"' + '\" \"'.join(list(zip(*eng_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bible': 1, 'coloring': 2, '은': 3, '성경의': 4, '아름다운': 5, '이야기를': 6, '체험': 7, '할': 8, '수': 9, '있는': 10, '컬러링': 11, '앱입니다': 12, '씨티은행에서': 13, '일하세요': 14, '푸리토의': 15, '베스트셀러는': 16, '해외에서': 17, '입소문만으로': 18, '4차': 19, '완판을': 20, '기록하였다': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  \"Bible Coloring\"은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
      "  Output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Sequence 2 in x\n",
      "  Input:  씨티은행에서 일하세요?\n",
      "  Output: [13, 14]\n",
      "Sequence 3 in x\n",
      "  Input:  푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.\n",
      "  Output: [15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "  \"\"\"\n",
    "  Tokenize x\n",
    "  :param x: List of sentences/strings to be tokenized\n",
    "  :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "  \"\"\"\n",
    "  # TODO: Implement\n",
    "  # tokenizer를 학습하고, 데이터를 bow로 만들어주세요\n",
    "\n",
    "  tknzer = Tokenizer()\n",
    "  tknzer.fit_on_texts(x)\n",
    "  data = tknzer.texts_to_sequences(x) # data = result of tokenizer\n",
    "\n",
    "  return data, tknzer\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    '\"Bible Coloring\"은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.',\n",
    "    '씨티은행에서 일하세요?',\n",
    "    '푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "  Output: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Sequence 2 in x\n",
      "  Input:  [13 14]\n",
      "  Output: [13 14  0  0  0  0  0  0  0  0  0  0]\n",
      "Sequence 3 in x\n",
      "  Input:  [15 16 17 18 19 20 21]\n",
      "  Output: [15 16 17 18 19 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    if length == None: \n",
    "        length = max(map(len, x))\n",
    "        padded = pad_sequences(x, maxlen=length, padding='post')\n",
    "    else:\n",
    "        padded = pad_sequences(x, maxlen=length, padding='post')\n",
    "\n",
    "    return np.array(padded) # sequence를 패딩하는 방법을 검색하여 사용하세요. \n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1)) # 내가 원하는 결과\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "최대 한국어 문장 길이: 30\n",
      "최대 영어 문장 길이: 53\n",
      "한국어 어휘 사전 크기: 202031\n",
      "영어 어휘 사전 크기: 40002\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_kor_sentences, preproc_eng_sentences, kor_tokenizer, eng_tokenizer =\\\n",
    "    preprocess(kor, eng)\n",
    "    \n",
    "max_kor_sequence_length = preproc_kor_sentences.shape[1]\n",
    "max_eng_sequence_length = preproc_eng_sentences.shape[1]\n",
    "kor_vocab_size = len(kor_tokenizer.word_index)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"최대 한국어 문장 길이:\", max_kor_sequence_length)\n",
    "print(\"최대 영어 문장 길이:\", max_eng_sequence_length)\n",
    "kor_vocab_size += 1\n",
    "eng_vocab_size += 1\n",
    "print(\"한국어 어휘 사전 크기:\", kor_vocab_size)\n",
    "print(\"영어 어휘 사전 크기:\", eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
