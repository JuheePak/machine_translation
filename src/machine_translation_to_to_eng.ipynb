{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBMKCkiKBtQp"
      },
      "source": [
        "#### 한-영번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpEjfUVaBqLa",
        "outputId": "567d2405-024f-4ff1-f4db-c47305f2276f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLW_iG6BlkD"
      },
      "source": [
        "import collections\r\n",
        "\r\n",
        "import helper\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knuW9wb3Blnb",
        "outputId": "ad6dc3e8-21c8-4880-b070-657d13ac8a72"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11954919717749950129\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14674281152\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12878680984660920125\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "NsdxCQU5CAlk",
        "outputId": "e46a5dc9-9c63-471b-fe7f-e7206ebf4dfb"
      },
      "source": [
        "import os, sys, time\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "df1 = pd.read_excel('/content/drive/MyDrive/machine_translator_project/data/1_구어체(1)_200226 (1).xlsx')\r\n",
        "df2 = pd.read_excel('/content/drive/MyDrive/machine_translator_project/data/1_구어체(1)_200226.xlsx')\r\n",
        "\r\n",
        "df = pd.concat([df1,df2])\r\n",
        "print(df.info()) # check rows\r\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 400000 entries, 0 to 199999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   SID     400000 non-null  int64 \n",
            " 1   원문      400000 non-null  object\n",
            " 2   번역문     400000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 12.2+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
              "      <td>Bible Coloring' is a coloring application that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>씨티은행에서 일하세요?</td>\n",
              "      <td>Do you work at a City bank?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
              "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
              "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
              "      <td>I would feel grateful to know how many stocks ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SID  ...                                                번역문\n",
              "0    1  ...  Bible Coloring' is a coloring application that...\n",
              "1    2  ...                        Do you work at a City bank?\n",
              "2    3  ...  PURITO's bestseller, which recorded 4th rough ...\n",
              "3    4  ...  In Chapter 11 Jesus called Lazarus from the to...\n",
              "4    5  ...  I would feel grateful to know how many stocks ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11xDyagRqM0"
      },
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa5jiY0RCArS",
        "outputId": "6eebc283-f4b8-47e8-b1ba-94b0171eef3b"
      },
      "source": [
        "df_korean_sentences = df.loc[1:50000, '원문']\r\n",
        "kor = df_korean_sentences.tolist()\r\n",
        "df_english_sentences = df.loc[1:50000, '번역문']\r\n",
        "eng = df_english_sentences.tolist()\r\n",
        "print(len(kor))\r\n",
        "print(len(eng)) # 50,000 rows"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYOXjeZeLXjN"
      },
      "source": [
        "# !pip install konlpy\r\n",
        "from konlpy.tag import Okt "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kgSpqgPfH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8efc50-b855-401f-bb01-bea9df285c79"
      },
      "source": [
        "def sen2morph(sentence):    \r\n",
        "    morphs = []    \r\n",
        "    analyzer = Okt()\r\n",
        "    morphs = analyzer.morphs(sentence)\r\n",
        "    return morphs\r\n",
        "morphs = sen2morph(kor[0])\r\n",
        "morphs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['씨티', '은행', '에서', '일', '하세요', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny23CcZcOV82"
      },
      "source": [
        "def load_preprocessed_data():\r\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\r\n",
        "    \r\n",
        "    for korean_sentence in kor:\r\n",
        "            src_line_input = sen2morph(korean_sentence)\r\n",
        "            encoder_input.append(src_line_input)\r\n",
        "        \r\n",
        "    for english_sentence in eng:\r\n",
        "            tar_line_input = [w for w in (\"<sos> \" + english_sentence).split()]\r\n",
        "            tar_line_target = [w for w in (english_sentence + \" <eos>\").split()]\r\n",
        "            decoder_input.append(tar_line_input)\r\n",
        "            decoder_target.append(tar_line_target)\r\n",
        "\r\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRXkvXPjOcwp",
        "outputId": "c9e82cf8-11d0-4e18-a242-e9a0aeeff118"
      },
      "source": [
        "sents_ko_in, sents_en_in, sents_en_out = load_preprocessed_data()\r\n",
        "print(sents_ko_in[:2])\r\n",
        "print(sents_en_in[:2])\r\n",
        "print(sents_en_out[:2])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['씨티', '은행', '에서', '일', '하세요', '?'], ['푸리', '토의', '베스트셀러', '는', '해외', '에서', '입', '소문', '만으로', '4', '차', '완판', '을', '기록', '하였다', '.']]\n",
            "[['<sos>', 'Do', 'you', 'work', 'at', 'a', 'City', 'bank?'], ['<sos>', \"PURITO's\", 'bestseller,', 'which', 'recorded', '4th', 'rough', '-cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad.']]\n",
            "[['Do', 'you', 'work', 'at', 'a', 'City', 'bank?', '<eos>'], [\"PURITO's\", 'bestseller,', 'which', 'recorded', '4th', 'rough', '-cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad.', '<eos>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daR4Yb2IZCiZ"
      },
      "source": [
        "#### tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYEgh8CYOnXK"
      },
      "source": [
        "tokenizer_ko = Tokenizer(filters=\"\", lower=False)\r\n",
        "tokenizer_ko.fit_on_texts(sents_ko_in)\r\n",
        "encoder_input = tokenizer_ko.texts_to_sequences(sents_ko_in)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yCa8uDFOqyn"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cWBxN8-SW04"
      },
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\r\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\r\n",
        "tokenizer_en.fit_on_texts(sents_en_out)\r\n",
        "decoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\r\n",
        "decoder_target = tokenizer_en.texts_to_sequences(sents_en_out)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJnzy6sGJqg5"
      },
      "source": [
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\r\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXeq9waUJqkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94707e84-aa8a-41af-d335-0edad78bc08b"
      },
      "source": [
        "src_vocab_size = len(tokenizer_ko.word_index) + 1\r\n",
        "print(\"한국어 단어 집합의 크기 : {:d}\".format(src_vocab_size))\r\n",
        "\r\n",
        "tar_vocab_size = len(tokenizer_en.word_index) + 1\r\n",
        "print(\"영어 단어 집합의 크기 : {:d}\".format(tar_vocab_size))\r\n",
        "\r\n",
        "src_to_index = tokenizer_ko.word_index\r\n",
        "index_to_src = tokenizer_ko.index_word # 훈련 후 결과 비교할 때 사용\r\n",
        "tar_to_index = tokenizer_en.word_index # 훈련 후 예측 과정에서 사용\r\n",
        "index_to_tar = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어 단어 집합의 크기 : 38546\n",
            "영어 단어 집합의 크기 : 39741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3C0rYk3JqoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa325a17-65a8-4c56-c7a9-46dff9e01997"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\r\n",
        "np.random.shuffle(indices)\r\n",
        "print(indices)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2912 32716  9408 ... 20967 34480  7803]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxfc4KZ5SmtW"
      },
      "source": [
        "encoder_input = encoder_input[indices]\r\n",
        "decoder_input = decoder_input[indices]\r\n",
        "decoder_target = decoder_target[indices]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj4nAY2sSo3b",
        "outputId": "8de4651c-58a2-4b97-bb91-76e1128859a7"
      },
      "source": [
        "n_of_val = int(50000*0.2)\r\n",
        "print(n_of_val)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqDNWOitSqeq"
      },
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\r\n",
        "decoder_input_train = decoder_input[:-n_of_val]\r\n",
        "decoder_target_train = decoder_target[:-n_of_val]\r\n",
        "\r\n",
        "encoder_input_test = encoder_input[-n_of_val:]\r\n",
        "decoder_input_test = decoder_input[-n_of_val:]\r\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TykeX7GSsE4",
        "outputId": "eecd3286-74ff-4b96-d63b-aacc874ede3e"
      },
      "source": [
        "print(encoder_input_train.shape)\r\n",
        "print(decoder_input_train.shape)\r\n",
        "print(decoder_target_train.shape)\r\n",
        "print(encoder_input_test.shape)\r\n",
        "print(decoder_input_test.shape)\r\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 37)\n",
            "(40000, 40)\n",
            "(40000, 40)\n",
            "(10000, 37)\n",
            "(10000, 40)\n",
            "(10000, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9rfwX0nSt8y"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "\r\n",
        "latent_dim = 512"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii4jMAuxSxWO",
        "outputId": "e1f30dae-ba12-422a-b40c-504893b1a330"
      },
      "source": [
        "# 인코더\r\n",
        "encoder_inputs = Input(shape=(None,))\r\n",
        "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\r\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\r\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\r\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\r\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장\r\n",
        "\r\n",
        "# 디코더\r\n",
        "decoder_inputs = Input(shape=(None,))\r\n",
        "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\r\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\r\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\r\n",
        "\r\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \r\n",
        "\r\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\r\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\r\n",
        "                                     initial_state=encoder_states)\r\n",
        "\r\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\r\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\r\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 512)    19735552    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 512)    20347392    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 512)    0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 512)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 512), (None, 2099200     masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 512),  2099200     masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 39741)  20387133    lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 64,668,477\n",
            "Trainable params: 64,668,477\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHk99fH7S2JJ",
        "outputId": "0bedff3d-b97b-4e97-9fb7-313dce0b28e0"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\r\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\r\n",
        "          batch_size = 128, epochs = 10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 192s 483ms/step - loss: 2.5913 - acc: 0.7137 - val_loss: 1.7422 - val_acc: 0.7607\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 150s 479ms/step - loss: 1.6850 - acc: 0.7638 - val_loss: 1.6264 - val_acc: 0.7708\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.5722 - acc: 0.7746 - val_loss: 1.5731 - val_acc: 0.7779\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.4862 - acc: 0.7828 - val_loss: 1.5304 - val_acc: 0.7817\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.4238 - acc: 0.7878 - val_loss: 1.5055 - val_acc: 0.7839\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 152s 487ms/step - loss: 1.3590 - acc: 0.7936 - val_loss: 1.4892 - val_acc: 0.7860\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.3006 - acc: 0.7993 - val_loss: 1.4758 - val_acc: 0.7876\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 152s 487ms/step - loss: 1.2505 - acc: 0.8041 - val_loss: 1.4682 - val_acc: 0.7888\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.2054 - acc: 0.8086 - val_loss: 1.4670 - val_acc: 0.7890\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 152s 486ms/step - loss: 1.1570 - acc: 0.8140 - val_loss: 1.4706 - val_acc: 0.7895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba4280da90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eoIS0NqS4yS"
      },
      "source": [
        "# 인코더\r\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\r\n",
        "\r\n",
        "# 디코더\r\n",
        "# 이전 시점의 상태를 보관할 텐서\r\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\r\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "\r\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\r\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\r\n",
        "\r\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\r\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\r\n",
        "decoder_states2 = [state_h2, state_c2]\r\n",
        "\r\n",
        "# 모든 시점에 대해서 단어 예측\r\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\r\n",
        "\r\n",
        "decoder_model = Model(\r\n",
        "    [decoder_inputs] + decoder_states_inputs,\r\n",
        "    [decoder_outputs2] + decoder_states2)\r\n",
        "\r\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW0BF9SFTDcw"
      },
      "source": [
        "def decode_sequence(input_seq):\r\n",
        "    # 입력으로부터 인코더의 상태를 얻음\r\n",
        "    states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "    # <SOS>에 해당하는 정수 생성\r\n",
        "    target_seq = np.zeros((1,1))\r\n",
        "    target_seq[0, 0] = tar_to_index['<sos>']\r\n",
        "\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = ''\r\n",
        "\r\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\r\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\r\n",
        "    while not stop_condition:\r\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\r\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\r\n",
        "\r\n",
        "        # 예측 결과를 단어로 변환\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "        sampled_char = index_to_tar[sampled_token_index]\r\n",
        "\r\n",
        "         # 현재 시점의 예측 단어를 예측 문장에 추가\r\n",
        "        decoded_sentence += ' '+sampled_char\r\n",
        "\r\n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\r\n",
        "        '''\r\n",
        "        if (sampled_char == '<eos>' or\r\n",
        "           len(decoded_sentence) > 50):\r\n",
        "            stop_condition = True\r\n",
        "        '''\r\n",
        "        if sampled_char == '<eos>':\r\n",
        "            stop_condition = True            \r\n",
        "\r\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\r\n",
        "        target_seq = np.zeros((1,1))\r\n",
        "        target_seq[0, 0] = sampled_token_index\r\n",
        "\r\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\r\n",
        "        states_value = [h, c]\r\n",
        "\r\n",
        "    return decoded_sentence"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdzjU32DTGkg"
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\r\n",
        "def seq2src(input_seq):\r\n",
        "    temp=''\r\n",
        "    for i in input_seq:\r\n",
        "        if(i!=0):\r\n",
        "            temp = temp + index_to_src[i]+' '\r\n",
        "    return temp\r\n",
        "\r\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\r\n",
        "def seq2tar(input_seq):\r\n",
        "    temp=''\r\n",
        "    for i in input_seq:\r\n",
        "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\r\n",
        "            temp = temp + index_to_tar[i] + ' '\r\n",
        "    return temp\r\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrA-HLRFTIsA",
        "outputId": "a919d1ff-c516-4fa2-bc80-ff447beff1dc"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]:\r\n",
        "    input_seq = encoder_input_train[seq_index: seq_index + 1]\r\n",
        "    decoded_sentence = decode_sequence(input_seq)\r\n",
        "\r\n",
        "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\r\n",
        "    print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\r\n",
        "    print(\"예측문 :\",decoded_sentence[:-5])\r\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  그렇다고 너무 낙심 하지는 마세요 . \n",
            "번역문 : Don't be so disappointed. \n",
            "예측문 :  I am not good at all. \n",
            "\n",
            "\n",
            "원문 :  나 는 늦게까지 교수 님 의 작업 을 도 왔어요 . \n",
            "번역문 : I helped the professor's work till late. \n",
            "예측문 :  I have a lot of time to go to the school. \n",
            "\n",
            "\n",
            "원문 :  그럼 네 가 말 한 건 , 한국 에서 남은 학기 등록금 과 생활비 를 내줄 수 있다는 건가 요 ? \n",
            "번역문 : Then what you said, did you mean that you can support the education fee and living expenses in Korea for the left semester? \n",
            "예측문 :  Then, is it okay to you and the Korean friends will be able to see the product with the same as soon as possible. \n",
            "\n",
            "\n",
            "원문 :  8월 12일 에 1 에서 2 로 , 7 에서 8 로 교체 하였고 . \n",
            "번역문 : It has been altered from 1 to 2, 7 to 8 on August 12th. \n",
            "예측문 :  I am sending the second floor to the 1st floor of the second floor of the 2nd floor. \n",
            "\n",
            "\n",
            "원문 :  나 는 남자 친구 를 멀리 서 봐야 했어요 . \n",
            "번역문 : I had to see my boyfriend from far away. \n",
            "예측문 :  I went to the same as I was in a high school. \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5M5G71hbHrM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}